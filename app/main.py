import os
import dotenv
from flask import Flask
from flask_socketio import SocketIO

from openai_advisor import InterviewAdvisor
from app.routes.views import views
from app.routes.sockets import register_socket_handlers

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv.load_dotenv(".env.keys", override=True)

# AI ì¡°ì–¸ì ì¸ìŠ¤í„´ìŠ¤
advisor = None

def init_ai_advisor():
    """AI ì¡°ì–¸ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    global advisor
    try:
        api_key = os.getenv("AZURE_OPENAI_KEY")
        endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        deployment_name = os.getenv("AZURE_OPENAI_MODEL", "gpt-4")

        if not all([api_key, endpoint, deployment_name]):
            print("âš ï¸ AI ì¡°ì–¸ ì‹œìŠ¤í…œ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            return False

        advisor = InterviewAdvisor(
            api_key=api_key,
            endpoint=endpoint,
            deployment_name=deployment_name,
        )
        print("ğŸ¤– AI ì¡°ì–¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        return True
    except Exception as e:
        print(f"âŒ AI ì¡°ì–¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

# Flask ì•±ê³¼ SocketIO ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = Flask(__name__)
socketio = SocketIO(
    app,
    cors_allowed_origins="*",
    async_mode="threading",
    ping_timeout=30,
    ping_interval=10,
    logger=False,
    engineio_logger=False,
)

# AI ì–´ë“œë°”ì´ì € ì´ˆê¸°í™” ì‹¤í–‰
init_ai_advisor()

# HTTP ë¼ìš°íŠ¸(Blueprint) ë“±ë¡
app.register_blueprint(views)

# SocketIO ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
register_socket_handlers(socketio, advisor)
